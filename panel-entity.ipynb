{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ab791d-14da-4b4d-b707-685d8e07a9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\dangkh\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from src.config import TrainConfig \n",
    "from src.ultis import *\n",
    "from src.data_helper import prepare_preprocessed_data\n",
    "from src.data_load import *\n",
    "from src.metrics import *\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.utils import subgraph\n",
    "\n",
    "from torch.utils.data import IterableDataset, Dataset\n",
    "from torch_geometric.loader import DataLoader as GraphDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129e3122-9b9f-43c3-87f8-1364326cbc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = TrainConfig\n",
    "\n",
    "device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device: torch.device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ddb2613-8bfb-4ab3-a65a-bff0bab3933a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 01:44:21,720 INFO Start\n",
      "2024-11-19 01:44:21,724 INFO Prepare the dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target_file is not exist. New behavior file in ./data/MINDsmall_train\\behaviors_np4_0.tsv\n",
      "./data/MINDsmall_train\\behaviors_np4_0.tsv ./data/MINDsmall_train\\behaviors.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156965it [00:02, 54539.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train]Writing files...\n",
      "Target_file is not exist. New behavior file in ./data/MINDsmall_val\\behaviors_np4_0.tsv\n",
      "./data/MINDsmall_val\\behaviors_np4_0.tsv ./data/MINDsmall_val\\behaviors.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73152it [00:00, 812503.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val]Writing files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[train]Processing raw news: 100%|██████████████████████████████████████████████| 51282/51282 [00:06<00:00, 8529.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing parsed news: 100%|████████████████████████████████████████████████| 51282/51282 [00:00<00:00, 176835.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove token preprocess finish.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[val]Processing raw news: 100%|████████████████████████████████████████████████| 42416/42416 [00:04<00:00, 9518.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing parsed news: 100%|████████████████████████████████████████████████| 65238/65238 [00:00<00:00, 170780.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove token preprocess finish.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[train] Processing behaviors news to News Graph: 100%|█████████████████████| 156965/156965 [00:00<00:00, 257742.72it/s]\n",
      "Processing news edge list: 100%|█████████████████████████████████████████████| 48304/48304 [00:00<00:00, 282482.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[51283, 27], edge_index=[2, 632044], edge_attr=[632044], num_nodes=51283)\n",
      "[train] Finish News Graph Construction, \n",
      "Graph Path: data\\MINDsmall_train\\nltk_news_graph.pt \n",
      "Graph Info: Data(x=[51283, 27], edge_index=[2, 632044], edge_attr=[632044], num_nodes=51283)\n",
      "[val] Finish nltk News Graph Construction, \n",
      "Graph Path: data\\MINDsmall_val\\nltk_news_graph.pt\n",
      "Graph Info: Data(x=[65239, 27], edge_index=[2, 632044], edge_attr=[632044], num_nodes=65239)\n",
      "[train] Start to process neighbors list\n",
      "[train] Finish news Neighbor dict \n",
      "Dict Path: data\\MINDsmall_train\\news_neighbor_dict.bin, \n",
      "Weight Dict: data\\MINDsmall_train\\news_weights_dict.bin\n",
      "[val] Start to process neighbors list\n",
      "[val] Finish news Neighbor dict \n",
      "Dict Path: data\\MINDsmall_val\\news_neighbor_dict.bin, \n",
      "Weight Dict: data\\MINDsmall_val\\news_weights_dict.bin\n",
      "news_graph, Data(x=[51283, 27], edge_index=[2, 632044], edge_attr=[632044], num_nodes=51283)\n",
      "entity_indices,  (51283, 5)\n",
      "[train] Finish Entity Graph Construction, \n",
      " Graph Path: data\\MINDsmall_train\\entity_graph.pt \n",
      "Graph Info: Data(x=[14991], edge_index=[2, 1233155], edge_attr=[1233155], num_nodes=14991)\n",
      "[val] Finish Entity Graph Construction, \n",
      " Graph Path: data\\MINDsmall_val\\entity_graph.pt \n",
      "Graph Info: Data(x=[17586], edge_index=[2, 1233155], edge_attr=[1233155], num_nodes=17586)\n",
      "[train] Start to process neighbors list\n",
      "[train] Finish entity Neighbor dict \n",
      "Dict Path: data\\MINDsmall_train\\entity_neighbor_dict.bin, \n",
      "Weight Dict: data\\MINDsmall_train\\entity_weights_dict.bin\n",
      "[val] Start to process neighbors list\n",
      "[val] Finish entity Neighbor dict \n",
      "Dict Path: data\\MINDsmall_val\\entity_neighbor_dict.bin, \n",
      "Weight Dict: data\\MINDsmall_val\\entity_weights_dict.bin\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Start\")\n",
    "set_random_seed(cfg.random_seed)\n",
    "\"\"\"\n",
    "0. Definite Parameters & Functions\n",
    "\n",
    "\"\"\"\n",
    "logging.info(\"Prepare the dataset\")\n",
    "prepare_preprocessed_data(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d675ac1-49b8-40d9-bb0f-72eb155356b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode='train'\n",
    "data_dir = {\"train\": cfg.data_dir + '_train', \"val\": cfg.data_dir + '_val', \"test\": cfg.data_dir}\n",
    "\n",
    "# ------------- load news.tsv-------------\n",
    "news_index = pickle.load(open(Path(data_dir[mode]) / \"news_dict.bin\", \"rb\"))\n",
    "news_input = pickle.load(open(Path(data_dir[mode]) / \"nltk_token_news.bin\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5237d0ce-f494-439e-8592-fd3947302030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51283, 27)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be0621d9-4d85-45e6-b060-60f0289ce1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] News Graph Info: Data(x=[51283, 27], edge_index=[2, 1171966], edge_attr=[1171966], num_nodes=51283)\n"
     ]
    }
   ],
   "source": [
    "target_file = Path(data_dir[mode]) / f\"behaviors_np{cfg.npratio}_0.tsv\"\n",
    "news_graph = torch.load(Path(data_dir[mode]) / \"nltk_news_graph.pt\")\n",
    "\n",
    "if cfg.directed is False:\n",
    "    news_graph.edge_index, news_graph.edge_attr = to_undirected(news_graph.edge_index, news_graph.edge_attr)\n",
    "print(f\"[{mode}] News Graph Info: {news_graph}\")\n",
    "\n",
    "news_neighbors_dict = pickle.load(open(Path(data_dir[mode]) / \"news_neighbor_dict.bin\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6589c7b5-449e-4734-b92b-e1b9b176202c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Dict length: 17585\n",
      "Have words: 28730\n",
      "Missing rate: -0.6337787887404037\n"
     ]
    }
   ],
   "source": [
    "entity_dict = pickle.load(open(Path(cfg.data_dir + '_val') / \"entity_dict.bin\", \"rb\"))\n",
    "entity_emb_path = Path(cfg.data_dir + '_val') / \"combined_entity_embedding.vec\"\n",
    "entity_emb = load_pretrain_emb(entity_emb_path, entity_dict, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de0d6874-d0cc-4edb-9835-c2d5498a04e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17586, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e675b-3843-4ae9-a8d5-616fb7748ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity_neighbors = pickle.load(open(Path(data_dir[mode]) / \"entity_neighbor_dict.bin\", \"rb\"))\n",
    "# total_length = sum(len(lst) for lst in entity_neighbors.values())\n",
    "# print(f\"[{mode}] entity_neighbor list Length: {total_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd74e17d-6309-4a94-a130-9f5108f4be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_PANEL_1(Dataset):\n",
    "    def __init__(self, filename, news_index, news_combined, cfg, neighbor_dict, news_graph):\n",
    "        super(Dataset_PANEL_1).__init__()\n",
    "        self.filename = filename\n",
    "        self.news_index = news_index\n",
    "        self.news_combined = news_combined\n",
    "        self.user_log_length = cfg.his_size\n",
    "        self.npratio = cfg.npratio\n",
    "        self.cfg = cfg\n",
    "        self.neighbor_dict = neighbor_dict\n",
    "        self.news_graph = news_graph\n",
    "        self.news_graph.x = self.news_graph.x.float()\n",
    "        self.prepare()\n",
    "\n",
    "    def trans_to_nindex(self, nids):\n",
    "        return [self.news_index[i] if i in self.news_index else 0 for i in nids]\n",
    "\n",
    "    def pad_to_fix_len(self, x, fix_length, padding_front=True, padding_value=0):\n",
    "        if padding_front:\n",
    "            pad_x = [padding_value] * (fix_length - len(x)) + x[-fix_length:]\n",
    "            mask = [0] * (fix_length - len(x)) + [1] * min(fix_length, len(x))\n",
    "        else:\n",
    "            pad_x = x[-fix_length:] + [padding_value] * (fix_length - len(x))\n",
    "            mask = [1] * min(fix_length, len(x)) + [0] * (fix_length - len(x))\n",
    "        return pad_x, np.array(mask, dtype='float32')\n",
    "\n",
    "    def build_k_hop(self, click_doc):\n",
    "        click_idx = [x for x in click_doc]\n",
    "        source_idx = [x for x in click_doc]\n",
    "        for _ in range(self.cfg.k_hops) :\n",
    "            current_hop_idx = []\n",
    "            for news_idx in source_idx:\n",
    "                current_hop_idx.extend(self.neighbor_dict[news_idx][:self.cfg.num_neighbors])\n",
    "            source_idx = current_hop_idx\n",
    "            click_idx.extend(current_hop_idx)\n",
    "        return list(set(click_idx))\n",
    "        \n",
    "    def prepare(self):\n",
    "        self.preprocessDT = []\n",
    "        with open(self.filename) as f:\n",
    "            for line in tqdm(f):\n",
    "                g, dt = self.line_mapper(line)\n",
    "                if len(g) == 0:\n",
    "                    continue\n",
    "                self.preprocessDT.append([g,dt])\n",
    "                # if len(self.preprocessDT) > 10000:\n",
    "                #     break\n",
    "    \n",
    "    def line_mapper(self, line):\n",
    "        line = line.strip().split('\\t')\n",
    "        click_docs = line[3].split()\n",
    "        sess_pos = line[4].split()\n",
    "        sess_neg = line[5].split()\n",
    "        click_docs = self.trans_to_nindex(click_docs)\n",
    "\n",
    "        # build sub-graph news\n",
    "        k_hops_click = self.build_k_hop(click_docs)\n",
    "        \n",
    "\n",
    "        # build sub-graph entity\n",
    "        click_docs, log_mask = self.pad_to_fix_len(click_docs, self.user_log_length)\n",
    "        user_feature = self.news_combined[click_docs]\n",
    "\n",
    "        pos = self.trans_to_nindex(sess_pos)\n",
    "        neg = self.trans_to_nindex(sess_neg)\n",
    "\n",
    "        label = random.randint(0, self.npratio)\n",
    "        sample_news = neg[:label] + pos + neg[label:]\n",
    "        news_feature = self.news_combined[sample_news]\n",
    "        return k_hops_click, [torch.from_numpy(user_feature), torch.from_numpy(log_mask), \\\n",
    "        torch.from_numpy(news_feature), torch.tensor(label)]\n",
    "\n",
    "    # def __iter__(self):\n",
    "    #     file_iter = open(self.filename)\n",
    "    #     return map(self.line_mapper, file_iter)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        k_hops_click, dt =  self.preprocessDT[idx]\n",
    "        # subemb = self.news_graph.x[k_hops_click]\n",
    "        # sub_edge_index, sub_edge_attr = subgraph(k_hops_click, self.news_graph.edge_index, self.news_graph.edge_attr, \\\n",
    "        #                                          relabel_nodes=True, num_nodes=self.news_graph.num_nodes)\n",
    "        # sub_news_graph = Data(x=subemb, edge_index=sub_edge_index, edge_attr=sub_edge_attr).cuda()\n",
    "        return \"\", dt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.preprocessDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4902e54f-cfe0-4e46-a1d2-9f4fb94a3adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "236344it [00:30, 7797.93it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset_PANEL_1(\n",
    "                filename=target_file,\n",
    "                news_index=news_index,\n",
    "                news_combined=news_input,\n",
    "                cfg=cfg,\n",
    "                neighbor_dict=news_neighbors_dict,\n",
    "                news_graph=news_graph\n",
    ")\n",
    "dataloader = GraphDataLoader(dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0b77c2f-5b08-41da-886d-a4064931c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84502714-78b3-4e44-a5df-530935c54695",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size):\n",
    "        super(AttentionPooling, self).__init__()\n",
    "        self.att_fc1 = nn.Linear(emb_size, hidden_size)\n",
    "        self.att_fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: batch_size, candidate_size, emb_dim\n",
    "            attn_mask: batch_size, candidate_size\n",
    "        Returns:\n",
    "            (shape) batch_size, emb_dim\n",
    "        \"\"\"\n",
    "        e = self.att_fc1(x)\n",
    "        e = nn.Tanh()(e)\n",
    "        alpha = self.att_fc2(e)\n",
    "        alpha = torch.exp(alpha)\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            alpha = alpha * attn_mask.unsqueeze(2)\n",
    "\n",
    "        alpha = alpha / (torch.sum(alpha, dim=1, keepdim=True) + 1e-8)\n",
    "        x = torch.bmm(x.permute(0, 2, 1), alpha).squeeze(dim=-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask=None):\n",
    "        '''\n",
    "            Q: batch_size, n_head, candidate_num, d_k\n",
    "            K: batch_size, n_head, candidate_num, d_k\n",
    "            V: batch_size, n_head, candidate_num, d_v\n",
    "            attn_mask: batch_size, n_head, candidate_num\n",
    "            Return: batch_size, n_head, candidate_num, d_v\n",
    "        '''\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(self.d_k)\n",
    "        scores = torch.exp(scores)\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            scores = scores * attn_mask.unsqueeze(dim=-2)\n",
    "\n",
    "        attn = scores / (torch.sum(scores, dim=-1, keepdim=True) + 1e-8)\n",
    "        context = torch.matmul(attn, V)\n",
    "        return context\n",
    "\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k, d_v):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads)\n",
    "\n",
    "        self.scaled_dot_product_attn = ScaledDotProductAttention(self.d_k)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight, gain=1)\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        '''\n",
    "            Q: batch_size, candidate_num, d_model\n",
    "            K: batch_size, candidate_num, d_model\n",
    "            V: batch_size, candidate_num, d_model\n",
    "            mask: batch_size, candidate_num\n",
    "        '''\n",
    "        batch_size = Q.shape[0]\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(dim=1).expand(-1, self.n_heads, -1)\n",
    "\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1, 2)\n",
    "\n",
    "        context = self.scaled_dot_product_attn(q_s, k_s, v_s, mask)\n",
    "        output = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_v)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e4eb076-b86c-4d29-997e-59ab12de9091",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsEncoder(nn.Module):\n",
    "    def __init__(self, embedding_matrix, num_category, num_subcategory):\n",
    "        super(NewsEncoder, self).__init__()\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.drop_rate = 0.2\n",
    "        self.num_words_title = 20\n",
    "        self.use_category = True\n",
    "        self.use_subcategory = True\n",
    "        category_emb_dim = 100\n",
    "        news_dim = 400\n",
    "        news_query_vector_dim = 200\n",
    "        word_embedding_dim = 300\n",
    "        self.category_emb = nn.Embedding(num_category + 1, category_emb_dim, padding_idx=0)\n",
    "        self.category_dense = nn.Linear(category_emb_dim, news_dim)\n",
    "        self.subcategory_emb = nn.Embedding(num_subcategory + 1, category_emb_dim, padding_idx=0)\n",
    "        self.subcategory_dense = nn.Linear(category_emb_dim, news_dim)\n",
    "        self.final_attn = AttentionPooling(news_dim, news_query_vector_dim)\n",
    "        self.cnn = nn.Conv1d(\n",
    "            in_channels=word_embedding_dim,\n",
    "            out_channels=news_dim,\n",
    "            kernel_size=3,\n",
    "            padding=1\n",
    "        )\n",
    "        self.attn = AttentionPooling(news_dim, news_query_vector_dim)\n",
    "        self.cln = nn.Linear(300,400)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        '''\n",
    "            x: batch_size, word_num\n",
    "            mask: batch_size, word_num\n",
    "        '''\n",
    "        title = torch.narrow(x, -1, 0, self.num_words_title).long()\n",
    "        word_vecs = F.dropout(self.embedding_matrix(title),\n",
    "                              p=self.drop_rate,\n",
    "                              training=self.training)\n",
    "        context_word_vecs = self.cnn(word_vecs.transpose(1, 2)).transpose(1, 2)\n",
    "        # context_word_vecs = self.cnn(word_vecs.transpose(1, 2)).transpose(1, 2)\n",
    "        # stop\n",
    "        title_vecs = self.attn(context_word_vecs, mask)\n",
    "        all_vecs = [title_vecs]\n",
    "\n",
    "        start = self.num_words_title\n",
    "        if self.use_category:\n",
    "            category = torch.narrow(x, -1, start, 1).squeeze(dim=-1).long()\n",
    "            category_vecs = self.category_dense(self.category_emb(category))\n",
    "            all_vecs.append(category_vecs)\n",
    "            start += 1\n",
    "        if self.use_subcategory:\n",
    "            subcategory = torch.narrow(x, -1, start, 1).squeeze(dim=-1).long()\n",
    "            subcategory_vecs = self.subcategory_dense(self.subcategory_emb(subcategory))\n",
    "            all_vecs.append(subcategory_vecs)\n",
    "\n",
    "        if len(all_vecs) == 1:\n",
    "            news_vecs = all_vecs[0]\n",
    "        else:\n",
    "            all_vecs = torch.stack(all_vecs, dim=1)\n",
    "            \n",
    "            news_vecs = self.final_attn(all_vecs)\n",
    "        return news_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f05fd2f-652d-4eaa-8da0-85f503ff1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UserEncoder, self).__init__()\n",
    "        news_dim = 400\n",
    "        user_query_vector_dim = 200\n",
    "        self.user_log_length = 50\n",
    "        self.user_log_mask = False\n",
    "        self.attn = AttentionPooling(news_dim, user_query_vector_dim)\n",
    "        self.pad_doc = nn.Parameter(torch.empty(1, news_dim).uniform_(-1, 1)).type(torch.FloatTensor)\n",
    "\n",
    "    def forward(self, news_vecs, log_mask=None):\n",
    "        '''\n",
    "            news_vecs: batch_size, history_num, news_dim\n",
    "            log_mask: batch_size, history_num\n",
    "        '''\n",
    "        bz = news_vecs.shape[0]\n",
    "        if self.user_log_mask:\n",
    "            user_vec = self.attn(news_vecs, log_mask)\n",
    "        else:\n",
    "            padding_doc = self.pad_doc.unsqueeze(dim=0).expand(bz, self.user_log_length, -1)\n",
    "            news_vecs = news_vecs * log_mask.unsqueeze(dim=-1) + padding_doc * (1 - log_mask.unsqueeze(dim=-1))\n",
    "            user_vec = self.attn(news_vecs)\n",
    "        return user_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7515df94-8dc4-44df-80e1-eb5bbd86d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityEncoder(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(EntityEncoder, self).__init__()\n",
    "\n",
    "        self.entity_dim = cfg.entity_emb_dim\n",
    "        self.news_dim = 400\n",
    "\n",
    "        self.mhat = MultiHeadSelfAttention(self.entity_dim, cfg.head_num , cfg.head_dim , cfg.head_dim)\n",
    "        self.mhat_dim = cfg.head_num * cfg.head_dim\n",
    "        self.lnorm = nn.LayerNorm(self.mhat_dim)\n",
    "        self.drop = nn.Dropout(p=cfg.dropout_probability)\n",
    "\n",
    "        self.att = AttentionPooling(self.mhat_dim, cfg.attention_hidden_dim)\n",
    "        self.ln = nn.Linear(self.mhat_dim, self.news_dim)\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, entity_input, entity_mask=None):\n",
    "\n",
    "        batch_size, num_news, num_entity, _ = entity_input.shape\n",
    "        entity_input = entity_input.view(-1, num_entity, self.entity_dim)\n",
    "        entity_input = self.drop(entity_input)\n",
    "        entity_input = self.mhat(entity_input, entity_input, entity_input)\n",
    "        entity_input = self.lnorm(entity_input)\n",
    "\n",
    "        entity_input = self.drop(entity_input)\n",
    "        entity_input = self.att(entity_input)\n",
    "        entity_input = self.lnorm(entity_input)\n",
    "        entity_input = self.ln(entity_input)\n",
    "        entity_input = self.act(entity_input)\n",
    "        \n",
    "        return  entity_input.view(batch_size, num_news, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ddaa5be1-8b93-41e0-a685-38c74b4ff8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NAML(torch.nn.Module):\n",
    "    def __init__(self, embedding_matrix, entity_emb, num_category, num_subcategory, **kwargs):\n",
    "        super(NAML, self).__init__()\n",
    "        self.news_dim = 400\n",
    "        self.entity_dim = 100\n",
    "        self.npratio = 4\n",
    "        self.user_log_length = 50\n",
    "        pretrained_word_embedding = torch.from_numpy(embedding_matrix).float()\n",
    "        word_embedding = nn.Embedding.from_pretrained(pretrained_word_embedding,\n",
    "                                                      freeze=False,\n",
    "                                                      padding_idx=0)\n",
    "        \n",
    "        pretrain = torch.from_numpy(entity_emb).float()\n",
    "        self.entity_embedding_layer = nn.Embedding.from_pretrained(pretrain, \n",
    "                                                                   freeze=False, \n",
    "                                                                   padding_idx=0)\n",
    "        \n",
    "        self.news_encoder = NewsEncoder( word_embedding, num_category, num_subcategory)\n",
    "        self.user_att = AttentionPooling(self.news_dim, cfg.attention_hidden_dim)\n",
    "        self.candi_att = AttentionPooling(self.news_dim, cfg.attention_hidden_dim)\n",
    "        self.user_encoder = UserEncoder()\n",
    "        self.entity_encoder = EntityEncoder(cfg)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, history, history_mask, candidate, label):\n",
    "        '''\n",
    "            history: batch_size, history_length, num_word_title\n",
    "            history_mask: batch_size, history_length\n",
    "            candidate: batch_size, 1+K, num_word_title\n",
    "            label: batch_size, 1+K\n",
    "        '''\n",
    "        e_his = history[:,:,-5:]\n",
    "        history = history[:,:,:-5]\n",
    "        e_candi = candidate[:,:,-5:]\n",
    "        candidate = candidate[:,:,:-5]\n",
    "        \n",
    "        # e_his = self.entity_embedding_layer(e_his)\n",
    "        # e_candi = self.entity_embedding_layer(e_candi)\n",
    "        # e_his = self.entity_encoder(e_his, None)\n",
    "        # e_candi = self.entity_encoder(e_candi, None)\n",
    "\n",
    "        # num_words = history.shape[-1]\n",
    "        # candidate = candidate.reshape(-1, num_words)\n",
    "        # candidate = self.news_encoder(candidate).reshape(-1, 1 + self.npratio, self.news_dim)\n",
    "        # candidate = self.candi_att(torch.stack([candidate, e_candi], dim=2).view(-1, 2, self.news_dim))\n",
    "        # candidate = candidate.view(-1, self.npratio+1, self.news_dim)\n",
    "\n",
    "        # history = history.reshape(-1, num_words)\n",
    "        # history = self.news_encoder(history).reshape(-1, self.user_log_length, self.news_dim)\n",
    "        # user_vec = self.user_att(torch.stack([history, e_his], dim=2).view(-1, 2, self.news_dim))\n",
    "        # user_vec = history.view(-1, self.user_log_length, self.news_dim)\n",
    "        \n",
    "        # user_vec = self.user_encoder(user_vec, history_mask)\n",
    "        \n",
    "        # score = torch.bmm(candidate, user_vec.unsqueeze(dim=-1)).squeeze(dim=-1)\n",
    "        # loss = self.loss_fn(score, label)\n",
    "\n",
    "        num_words = history.shape[-1]\n",
    "        candidate_news = candidate.reshape(-1, num_words)\n",
    "        candidate_news_vecs = self.news_encoder(candidate_news).reshape(-1, 1 + self.npratio, self.news_dim)\n",
    "        history_news = history.reshape(-1, num_words)\n",
    "        history_news_vecs = self.news_encoder(history_news).reshape(-1, self.user_log_length, self.news_dim)\n",
    "        user_vec = self.user_encoder(history_news_vecs, history_mask)\n",
    "        score = torch.bmm(candidate_news_vecs, user_vec.unsqueeze(dim=-1)).squeeze(dim=-1)\n",
    "        loss = self.loss_fn(score, label)\n",
    "        \n",
    "        return loss, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39f02757-1e70-4cd5-b950-5b41bdfa1b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Dict length: 12506\n",
      "Have words: 11947\n",
      "Missing rate: 0.0446985446985447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12506"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_dict = pickle.load(open(os.path.join(cfg.data_dir + '_train', \"category_dict.bin\"), \"rb\"))\n",
    "subcategory_dict = pickle.load(open(os.path.join(cfg.data_dir + '_train', \"subcategory_dict.bin\"), \"rb\"))\n",
    "word_dict = pickle.load(open(os.path.join(cfg.data_dir + '_train', \"word_dict.bin\"), \"rb\"))\n",
    "glove_emb = load_pretrain_emb(cfg.glove_path, word_dict, cfg.word_emb_dim)\n",
    "len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42ab74c3-be64-4f83-856c-e0eab5720c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_true, y_hat):\n",
    "    y_hat = torch.argmax(y_hat, dim=-1)\n",
    "    tot = y_true.shape[0]\n",
    "    hit = torch.sum(y_true == y_hat)\n",
    "    return hit.data.float() * 1.0 / tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b1fc4f7-bb86-403e-8582-da8bcf6ad281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAML(\n",
       "  (entity_embedding_layer): Embedding(17586, 100, padding_idx=0)\n",
       "  (news_encoder): NewsEncoder(\n",
       "    (embedding_matrix): Embedding(12507, 300, padding_idx=0)\n",
       "    (category_emb): Embedding(18, 100, padding_idx=0)\n",
       "    (category_dense): Linear(in_features=100, out_features=400, bias=True)\n",
       "    (subcategory_emb): Embedding(265, 100, padding_idx=0)\n",
       "    (subcategory_dense): Linear(in_features=100, out_features=400, bias=True)\n",
       "    (final_attn): AttentionPooling(\n",
       "      (att_fc1): Linear(in_features=400, out_features=200, bias=True)\n",
       "      (att_fc2): Linear(in_features=200, out_features=1, bias=True)\n",
       "    )\n",
       "    (cnn): Conv1d(300, 400, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (attn): AttentionPooling(\n",
       "      (att_fc1): Linear(in_features=400, out_features=200, bias=True)\n",
       "      (att_fc2): Linear(in_features=200, out_features=1, bias=True)\n",
       "    )\n",
       "    (cln): Linear(in_features=300, out_features=400, bias=True)\n",
       "  )\n",
       "  (user_att): AttentionPooling(\n",
       "    (att_fc1): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (att_fc2): Linear(in_features=200, out_features=1, bias=True)\n",
       "  )\n",
       "  (candi_att): AttentionPooling(\n",
       "    (att_fc1): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (att_fc2): Linear(in_features=200, out_features=1, bias=True)\n",
       "  )\n",
       "  (user_encoder): UserEncoder(\n",
       "    (attn): AttentionPooling(\n",
       "      (att_fc1): Linear(in_features=400, out_features=200, bias=True)\n",
       "      (att_fc2): Linear(in_features=200, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (entity_encoder): EntityEncoder(\n",
       "    (mhat): MultiHeadSelfAttention(\n",
       "      (W_Q): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (W_K): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (W_V): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (scaled_dot_product_attn): ScaledDotProductAttention()\n",
       "    )\n",
       "    (lnorm): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "    (drop): Dropout(p=0.2, inplace=False)\n",
       "    (att): AttentionPooling(\n",
       "      (att_fc1): Linear(in_features=100, out_features=200, bias=True)\n",
       "      (att_fc2): Linear(in_features=200, out_features=1, bias=True)\n",
       "    )\n",
       "    (ln): Linear(in_features=100, out_features=400, bias=True)\n",
       "    (act): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NAML(glove_emb, entity_emb, len(category_dict), len(subcategory_dict))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
    "model = model.to(device)\n",
    "torch.set_grad_enabled(True)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "710d3bc3-675e-4a00-91a5-a77c9ccd3475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1809it [01:54, 15.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2492.1538, device='cuda:0') tensor(789.3857, device='cuda:0')\n",
      "EPOCH: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1809it [01:52, 16.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2365.7339, device='cuda:0') tensor(856.3138, device='cuda:0')\n",
      "EPOCH: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1809it [01:54, 15.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2313.7361, device='cuda:0') tensor(881.1702, device='cuda:0')\n",
      "EPOCH: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1809it [01:53, 15.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2270.9907, device='cuda:0') tensor(902.1985, device='cuda:0')\n",
      "EPOCH: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1809it [01:54, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2233.1731, device='cuda:0') tensor(919.5345, device='cuda:0')\n",
      "EPOCH: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1809it [01:54, 15.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2194.6487, device='cuda:0') tensor(937.0800, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ep in range(6):\n",
    "    loss = 0.0\n",
    "    accuary = 0.0\n",
    "    print(\"EPOCH: \" + str(ep))\n",
    "    for cnt, (_, [log_ids, log_mask, input_ids, targets]) in tqdm(enumerate(dataloader)):\n",
    "        log_ids = log_ids.to(device)\n",
    "        log_mask = log_mask.to(device)\n",
    "        input_ids = input_ids.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        bz_loss, y_hat = model(log_ids, log_mask, input_ids, targets)\n",
    "        loss += bz_loss.data.float()\n",
    "        accuary += acc(targets, y_hat)\n",
    "        optimizer.zero_grad()\n",
    "        bz_loss.backward()\n",
    "        optimizer.step()\n",
    "        # stop\n",
    "    print(loss, accuary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619ceb00-d40f-426c-94b3-3bd4646dcfa3",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94ac9e3a-5b13-446f-bf6f-171c99d24cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d066192f-25d9-4a1a-b1c7-dab919a97df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x2dcbbf81910>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0c734545-520a-4773-90d7-dc0cfa911166",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"val\"\n",
    "data_dir = {\"train\": cfg.data_dir + '_train', \"val\": cfg.data_dir + '_val', \"test\": cfg.data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8710744c-91ff-48f0-8026-9c94c5685323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': './data/MINDsmall_train',\n",
       " 'val': './data/MINDsmall_val',\n",
       " 'test': './data/MINDsmall'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e48bd4e7-628e-4a12-8a7e-78b5328a9b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/MINDsmall_val'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_index_valid = pickle.load(open(Path(data_dir[mode]) / \"news_dict.bin\", \"rb\"))\n",
    "news_input_valid = pickle.load(open(Path(data_dir[mode]) / \"nltk_token_news.bin\", \"rb\"))\n",
    "data_dir[mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "49fef80e-89fd-4e64-b218-8401da02d2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65238"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_index_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6768039c-b691-453c-84ba-4b31c9bad228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65239, 27)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_input_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39596d22-f1bc-4945-a650-c38372afeb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dataset = NewsDataset(news_input_valid)\n",
    "news_dataloader = DataLoader(news_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a3ce4-9bea-4357-ac10-841486f56bcf",
   "metadata": {},
   "source": [
    "## news -> scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9142bf3b-4d4e-4094-91bb-5a024a647abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 510/510 [00:01<00:00, 392.42it/s]\n"
     ]
    }
   ],
   "source": [
    "news_scoring = []\n",
    "maxE = 0\n",
    "with torch.no_grad():\n",
    "    for input_ids in tqdm(news_dataloader):\n",
    "        e_lis = input_ids[:,-5:]\n",
    "        input_ids = input_ids[:,:-5].cuda()\n",
    "        news_vec = model.news_encoder(input_ids)\n",
    "        news_vec = news_vec.to(torch.device(\"cpu\"))\n",
    "        news_vec = torch.concatenate((news_vec, e_lis),-1)\n",
    "        news_vec = news_vec.detach().numpy()\n",
    "        news_scoring.extend(news_vec)\n",
    "\n",
    "news_scoring = np.array(news_scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b6dbe-19ba-40a6-89be-ab292c9c0791",
   "metadata": {},
   "source": [
    "## val loader and compute score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e664e0d-dae5-4cb9-b7f3-775b9939472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidDataset_PANEL_1(Dataset_PANEL_1):\n",
    "    def __init__(self, filename, news_index, news_score, cfg, neighbor_dict, news_graph):\n",
    "        super(Dataset_PANEL_1).__init__()\n",
    "        self.filename = filename\n",
    "        self.news_index = news_index\n",
    "        self.news_score = news_score\n",
    "        self.user_log_length = cfg.his_size\n",
    "        self.npratio = cfg.npratio\n",
    "        self.cfg = cfg\n",
    "        self.neighbor_dict = neighbor_dict\n",
    "        self.news_graph = news_graph\n",
    "        self.news_graph.x = self.news_graph.x.float()\n",
    "        self.prepare()\n",
    "        \n",
    "\n",
    "    def line_mapper(self, line):\n",
    "        line = line.strip().split('\\t')\n",
    "        click_docs = line[3].split()\n",
    "        \n",
    "        candidate_news = self.trans_to_nindex([i.split('-')[0] for i in line[4].split()])\n",
    "        label = np.array([int(i.split('-')[1]) for i in line[4].split()])\n",
    "        \n",
    "        click_docs = self.trans_to_nindex(click_docs)\n",
    "\n",
    "        # build sub-graph\n",
    "        k_hops_click = self.build_k_hop(click_docs)\n",
    "        \n",
    "        click_docs, log_mask = self.pad_to_fix_len(click_docs, self.user_log_length)\n",
    "        user_feature = self.news_score[click_docs]\n",
    "\n",
    "        news_feature = self.news_score[candidate_news]\n",
    "        \n",
    "        return k_hops_click,  [torch.from_numpy(user_feature), torch.from_numpy(log_mask), \\\n",
    "        torch.from_numpy(news_feature), torch.tensor(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "098ac2d6-3047-4e0d-8e5f-b33f0d19254e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('data/MINDsmall_val/behaviors.tsv')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_file_valid = Path(data_dir[mode]) / f\"behaviors.tsv\"\n",
    "target_file_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0cc6c9c4-9065-4ddb-98db-af4381ba7d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_graph_valid = torch.load(Path(data_dir[mode]) / \"nltk_news_graph.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1774a9e9-5684-4d1e-8618-5e154dd20523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73152it [01:11, 1017.89it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = ValidDataset_PANEL_1(\n",
    "                filename=target_file_valid,\n",
    "                news_index=news_index_valid,\n",
    "                news_score=news_scoring,\n",
    "                cfg=cfg,\n",
    "                neighbor_dict=news_neighbors_dict,\n",
    "                news_graph=news_graph_valid\n",
    ")\n",
    "valid_dataloader = GraphDataLoader(valid_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "093e3b3e-214a-4958-a7bd-dbe9c8f4f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_metrics(cnt, x):\n",
    "    print(cnt, x)\n",
    "\n",
    "def get_mean(arr):\n",
    "    return [np.array(i).mean() for i in arr]\n",
    "\n",
    "def get_sum(arr):\n",
    "    return [np.array(i).sum() for i in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c70af8bf-0d03-4900-bab4-7913cd5ab743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:01, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.8571428571428572, 0.25, 0.43067655807339306, 0.43067655807339306]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10032it [00:53, 232.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 [0.6624462543722827, 0.3170191751402499, 0.35070534751212035, 0.41315035215068135]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20072it [01:26, 312.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 [0.6641737768210804, 0.31971030433909947, 0.3533455861583569, 0.41521781168443045]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30039it [01:58, 304.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 [0.6618817514963073, 0.31851488945234707, 0.35188740871657126, 0.4140881362769402]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40042it [02:32, 292.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 [0.6615301627537675, 0.31735061305543194, 0.3506270414949011, 0.4134534158321934]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50053it [03:08, 314.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 [0.6615160972993133, 0.3164111321140924, 0.3496303668246948, 0.41231014073886885]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60046it [03:40, 290.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 [0.6614175273178696, 0.3164653181928461, 0.349784532301069, 0.4124487996077191]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70072it [04:12, 325.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000 [0.6612616685552216, 0.3170137150085818, 0.35045546936889094, 0.41331923085552486]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70938it [04:14, 278.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70937 [0.661124061401505, 0.3167743084213944, 0.3502043513618069, 0.4130480530599741]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "AUC = []\n",
    "MRR = []\n",
    "nDCG5 = []\n",
    "nDCG10 = []\n",
    "\n",
    "for cnt, (_, [log_vecs, log_mask, news_vecs, labels]) in tqdm(enumerate(valid_dataloader)):\n",
    "    log_vecs = log_vecs.cuda()\n",
    "    log_mask = log_mask.cuda()\n",
    "    # news_vecs = news_vecs.cuda()\n",
    "    \n",
    "\n",
    "    e_his = log_vecs[:,:,-5:].int()\n",
    "    log_vecs = log_vecs[:,:,:-5]\n",
    "    e_candi = news_vecs[:,:,-5:].int()\n",
    "    news_vecs = news_vecs[:,:,:-5]\n",
    "\n",
    "    # e_his = model.entity_embedding_layer(e_his)\n",
    "    # e_candi = model.entity_embedding_layer(e_candi)\n",
    "    # e_his = model.entity_encoder(e_his, None)\n",
    "    # e_candi = model.entity_encoder(e_candi, None)\n",
    "    \n",
    "    # user_vecs = model.user_att(torch.stack([log_vecs, e_his], dim=2).view(-1, 2, model.news_dim))\n",
    "    # user_vecs = user_vecs.view(-1, model.user_log_length, model.news_dim)\n",
    "\n",
    "    user_vecs = log_vecs.view(-1, model.user_log_length, model.news_dim)\n",
    "\n",
    "    \n",
    "    user_vecs = model.user_encoder(user_vecs, log_mask).to(torch.device(\"cpu\")).detach().numpy()\n",
    "    \n",
    "    # news_vecs = model.candi_att(torch.stack([news_vecs, e_candi], dim=2).view(-1, 2, model.news_dim))\n",
    "    # news_vecs = news_vecs.unsqueeze(0).to(torch.device(\"cpu\")).detach().numpy()\n",
    "\n",
    "    \n",
    "    # candidate = candidate.view(-1, model.npratio+1, self.news_dim)\n",
    "    # (1, 400) torch.Size([1, 22, 400]) (1, 22)\n",
    "\n",
    "    labels = labels.to(torch.device(\"cpu\")).detach().numpy()\n",
    "\n",
    "    for user_vec, news_vec, label in zip(user_vecs, news_vecs, labels):\n",
    "        tmp = np.mean(label)\n",
    "        if tmp == 0 or tmp == 1:\n",
    "            continue\n",
    "\n",
    "        score = np.dot(news_vec, user_vec)\n",
    "        auc = roc_auc_score(label, score)\n",
    "        mrr = mrr_score(label, score)\n",
    "        ndcg5 = ndcg_score(label, score, k=5)\n",
    "        ndcg10 = ndcg_score(label, score, k=10)\n",
    "\n",
    "        AUC.append(auc)\n",
    "        MRR.append(mrr)\n",
    "        nDCG5.append(ndcg5)\n",
    "        nDCG10.append(ndcg10)\n",
    "\n",
    "    if cnt % 10000 == 0:\n",
    "        print_metrics(cnt, get_mean([AUC, MRR, nDCG5, nDCG10]))\n",
    "\n",
    "print_metrics(cnt, get_mean([AUC, MRR, nDCG5, nDCG10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
