{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ab791d-14da-4b4d-b707-685d8e07a9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\dangkh\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from src.config import TrainConfig \n",
    "from src.ultis import *\n",
    "from src.data_helper import prepare_preprocessed_data\n",
    "from src.data_load import *\n",
    "from src.metrics import *\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.utils import subgraph\n",
    "\n",
    "from torch.utils.data import IterableDataset, Dataset\n",
    "from torch_geometric.loader import DataLoader as GraphDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129e3122-9b9f-43c3-87f8-1364326cbc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = TrainConfig\n",
    "\n",
    "device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device: torch.device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ddb2613-8bfb-4ab3-a65a-bff0bab3933a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 02:20:17,131 INFO Start\n",
      "2024-11-22 02:20:17,135 INFO Prepare the dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] All preprocessed files exist.\n",
      "[val] All preprocessed files exist.\n",
      "[train] All graphs exist !\n",
      "[val] All graphs exist !\n",
      "[train] Start to process neighbors list\n",
      "[train] All news Neighbor dict exist !\n",
      "[val] Start to process neighbors list\n",
      "[val] All news Neighbor dict exist !\n",
      "[train] Entity graph exists!\n",
      "[val] Entity graph exists!\n",
      "[train] Start to process neighbors list\n",
      "[train] All entity Neighbor dict exist !\n",
      "[val] Start to process neighbors list\n",
      "[val] All entity Neighbor dict exist !\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Start\")\n",
    "set_random_seed(cfg.random_seed)\n",
    "\"\"\"\n",
    "0. Definite Parameters & Functions\n",
    "\n",
    "\"\"\"\n",
    "logging.info(\"Prepare the dataset\")\n",
    "prepare_preprocessed_data(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d675ac1-49b8-40d9-bb0f-72eb155356b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode='train'\n",
    "data_dir = {\"train\": cfg.data_dir + '_train', \"val\": cfg.data_dir + '_val', \"test\": cfg.data_dir}\n",
    "\n",
    "# ------------- load news.tsv-------------\n",
    "news_index = pickle.load(open(Path(data_dir[mode]) / \"news_dict.bin\", \"rb\"))\n",
    "news_input = pickle.load(open(Path(data_dir[mode]) / \"nltk_token_news.bin\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5237d0ce-f494-439e-8592-fd3947302030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51283, 27)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be0621d9-4d85-45e6-b060-60f0289ce1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] News Graph Info: Data(x=[51283, 27], edge_index=[2, 1171966], edge_attr=[1171966], num_nodes=51283)\n"
     ]
    }
   ],
   "source": [
    "target_file = Path(data_dir[mode]) / f\"behaviors_np{cfg.npratio}_0.tsv\"\n",
    "news_graph = torch.load(Path(data_dir[mode]) / \"nltk_news_graph.pt\")\n",
    "\n",
    "if cfg.directed is False:\n",
    "    news_graph.edge_index, news_graph.edge_attr = to_undirected(news_graph.edge_index, news_graph.edge_attr)\n",
    "print(f\"[{mode}] News Graph Info: {news_graph}\")\n",
    "\n",
    "news_neighbors_dict = pickle.load(open(Path(data_dir[mode]) / \"news_neighbor_dict.bin\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6589c7b5-449e-4734-b92b-e1b9b176202c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Dict length: 17585\n",
      "Have words: 28730\n",
      "Missing rate: -0.6337787887404037\n"
     ]
    }
   ],
   "source": [
    "entity_dict = pickle.load(open(Path(cfg.data_dir + '_val') / \"entity_dict.bin\", \"rb\"))\n",
    "entity_emb_path = Path(cfg.data_dir + '_val') / \"combined_entity_embedding.vec\"\n",
    "entity_emb = load_pretrain_emb(entity_emb_path, entity_dict, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de0d6874-d0cc-4edb-9835-c2d5498a04e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17586, 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd74e17d-6309-4a94-a130-9f5108f4be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_PANEL_1(Dataset):\n",
    "    def __init__(self, filename, news_index, news_combined, cfg, neighbor_dict, news_graph):\n",
    "        super(Dataset_PANEL_1).__init__()\n",
    "        self.filename = filename\n",
    "        self.news_index = news_index\n",
    "        self.news_combined = news_combined\n",
    "        self.user_log_length = cfg.his_size\n",
    "        self.npratio = cfg.npratio\n",
    "        self.cfg = cfg\n",
    "        self.neighbor_dict = neighbor_dict\n",
    "        self.news_graph = news_graph\n",
    "        self.news_graph.x = self.news_graph.x.float()\n",
    "        self.prepare()\n",
    "\n",
    "    def trans_to_nindex(self, nids):\n",
    "        return [self.news_index[i] if i in self.news_index else 0 for i in nids]\n",
    "\n",
    "    def pad_to_fix_len(self, x, fix_length, padding_front=True, padding_value=0):\n",
    "        if padding_front:\n",
    "            pad_x = [padding_value] * (fix_length - len(x)) + x[-fix_length:]\n",
    "            mask = [0] * (fix_length - len(x)) + [1] * min(fix_length, len(x))\n",
    "        else:\n",
    "            pad_x = x[-fix_length:] + [padding_value] * (fix_length - len(x))\n",
    "            mask = [1] * min(fix_length, len(x)) + [0] * (fix_length - len(x))\n",
    "        return pad_x, np.array(mask, dtype='float32')\n",
    "\n",
    "    def build_k_hop(self, click_doc):\n",
    "        click_idx = [x for x in click_doc]\n",
    "        source_idx = [x for x in click_doc]\n",
    "        for _ in range(self.cfg.k_hops) :\n",
    "            current_hop_idx = []\n",
    "            for news_idx in source_idx:\n",
    "                current_hop_idx.extend(self.neighbor_dict[news_idx][:self.cfg.num_neighbors])\n",
    "            source_idx = current_hop_idx\n",
    "            click_idx.extend(current_hop_idx)\n",
    "        return list(set(click_idx))\n",
    "        \n",
    "    def prepare(self):\n",
    "        self.preprocessDT = []\n",
    "        with open(self.filename) as f:\n",
    "            for line in tqdm(f):\n",
    "                g, dt = self.line_mapper(line)\n",
    "                if len(g) == 0:\n",
    "                    continue\n",
    "                self.preprocessDT.append([g,dt])\n",
    "                if len(self.preprocessDT) > 10000:\n",
    "                    break\n",
    "    \n",
    "    def line_mapper(self, line):\n",
    "        line = line.strip().split('\\t')\n",
    "        click_docs = line[3].split()\n",
    "        sess_pos = line[4].split()\n",
    "        sess_neg = line[5].split()\n",
    "        click_docs = self.trans_to_nindex(click_docs)\n",
    "\n",
    "        # build sub-graph news\n",
    "        k_hops_click = self.build_k_hop(click_docs)\n",
    "        \n",
    "\n",
    "        # build sub-graph entity\n",
    "        click_docs, log_mask = self.pad_to_fix_len(click_docs, self.user_log_length)\n",
    "        user_feature = self.news_combined[click_docs]\n",
    "\n",
    "        pos = self.trans_to_nindex(sess_pos)\n",
    "        neg = self.trans_to_nindex(sess_neg)\n",
    "\n",
    "        label = random.randint(0, self.npratio)\n",
    "        sample_news = neg[:label] + pos + neg[label:]\n",
    "        news_feature = self.news_combined[sample_news]\n",
    "        return k_hops_click, [torch.from_numpy(user_feature), torch.from_numpy(log_mask), \\\n",
    "        torch.from_numpy(news_feature), torch.tensor(label)]\n",
    "\n",
    "    # def __iter__(self):\n",
    "    #     file_iter = open(self.filename)\n",
    "    #     return map(self.line_mapper, file_iter)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        k_hops_click, dt =  self.preprocessDT[idx]\n",
    "        # subemb = self.news_graph.x[k_hops_click]\n",
    "        # sub_edge_index, sub_edge_attr = subgraph(k_hops_click, self.news_graph.edge_index, self.news_graph.edge_attr, \\\n",
    "        #                                          relabel_nodes=True, num_nodes=self.news_graph.num_nodes)\n",
    "        # sub_news_graph = Data(x=subemb, edge_index=sub_edge_index, edge_attr=sub_edge_attr).cuda()\n",
    "        return \"\", dt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.preprocessDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4902e54f-cfe0-4e46-a1d2-9f4fb94a3adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10172it [00:01, 7176.97it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset_PANEL_1(\n",
    "                filename=target_file,\n",
    "                news_index=news_index,\n",
    "                news_combined=news_input,\n",
    "                cfg=cfg,\n",
    "                neighbor_dict=news_neighbors_dict,\n",
    "                news_graph=news_graph\n",
    ")\n",
    "dataloader = GraphDataLoader(dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0b77c2f-5b08-41da-886d-a4064931c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84502714-78b3-4e44-a5df-530935c54695",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size):\n",
    "        super(AttentionPooling, self).__init__()\n",
    "        self.att_fc1 = nn.Linear(emb_size, hidden_size)\n",
    "        self.att_fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, attn_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: batch_size, candidate_size, emb_dim\n",
    "            attn_mask: batch_size, candidate_size\n",
    "        Returns:\n",
    "            (shape) batch_size, emb_dim\n",
    "        \"\"\"\n",
    "        e = self.att_fc1(x)\n",
    "        e = nn.Tanh()(e)\n",
    "        alpha = self.att_fc2(e)\n",
    "        alpha = torch.exp(alpha)\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            alpha = alpha * attn_mask.unsqueeze(2)\n",
    "\n",
    "        alpha = alpha / (torch.sum(alpha, dim=1, keepdim=True) + 1e-8)\n",
    "        x = torch.bmm(x.permute(0, 2, 1), alpha).squeeze(dim=-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask=None):\n",
    "        '''\n",
    "            Q: batch_size, n_head, candidate_num, d_k\n",
    "            K: batch_size, n_head, candidate_num, d_k\n",
    "            V: batch_size, n_head, candidate_num, d_v\n",
    "            attn_mask: batch_size, n_head, candidate_num\n",
    "            Return: batch_size, n_head, candidate_num, d_v\n",
    "        '''\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(self.d_k)\n",
    "        scores = torch.exp(scores)\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            scores = scores * attn_mask.unsqueeze(dim=-2)\n",
    "\n",
    "        attn = scores / (torch.sum(scores, dim=-1, keepdim=True) + 1e-8)\n",
    "        context = torch.matmul(attn, V)\n",
    "        return context\n",
    "\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k, d_v):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads)\n",
    "\n",
    "        self.scaled_dot_product_attn = ScaledDotProductAttention(self.d_k)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight, gain=1)\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        '''\n",
    "            Q: batch_size, candidate_num, d_model\n",
    "            K: batch_size, candidate_num, d_model\n",
    "            V: batch_size, candidate_num, d_model\n",
    "            mask: batch_size, candidate_num\n",
    "        '''\n",
    "        batch_size = Q.shape[0]\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(dim=1).expand(-1, self.n_heads, -1)\n",
    "\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1, 2)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1, 2)\n",
    "\n",
    "        context = self.scaled_dot_product_attn(q_s, k_s, v_s, mask)\n",
    "        output = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_v)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e4eb076-b86c-4d29-997e-59ab12de9091",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsEncoder(nn.Module):\n",
    "    def __init__(self, embedding_matrix, num_category, num_subcategory):\n",
    "        super(NewsEncoder, self).__init__()\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.drop_rate = 0.2\n",
    "        self.num_words_title = 20\n",
    "        self.use_category = True\n",
    "        self.use_subcategory = True\n",
    "        category_emb_dim = 100\n",
    "        news_dim = 400\n",
    "        news_query_vector_dim = 200\n",
    "        word_embedding_dim = 300\n",
    "        self.category_emb = nn.Embedding(num_category + 1, category_emb_dim, padding_idx=0)\n",
    "        self.category_dense = nn.Linear(category_emb_dim, news_dim)\n",
    "        self.subcategory_emb = nn.Embedding(num_subcategory + 1, category_emb_dim, padding_idx=0)\n",
    "        self.subcategory_dense = nn.Linear(category_emb_dim, news_dim)\n",
    "        self.final_attn = AttentionPooling(news_dim, news_query_vector_dim)\n",
    "        self.cnn = nn.Conv1d(\n",
    "            in_channels=word_embedding_dim,\n",
    "            out_channels=news_dim,\n",
    "            kernel_size=3,\n",
    "            padding=1\n",
    "        )\n",
    "        self.attn = AttentionPooling(news_dim, news_query_vector_dim)\n",
    "        self.cln = nn.Linear(300,400)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        '''\n",
    "            x: batch_size, word_num\n",
    "            mask: batch_size, word_num\n",
    "        '''\n",
    "        title = torch.narrow(x, -1, 0, self.num_words_title).long()\n",
    "        word_vecs = F.dropout(self.embedding_matrix(title),\n",
    "                              p=self.drop_rate,\n",
    "                              training=self.training)\n",
    "        context_word_vecs = self.cnn(word_vecs.transpose(1, 2)).transpose(1, 2)\n",
    "        # context_word_vecs = self.cnn(word_vecs.transpose(1, 2)).transpose(1, 2)\n",
    "        # stop\n",
    "        title_vecs = self.attn(context_word_vecs, mask)\n",
    "        all_vecs = [title_vecs]\n",
    "\n",
    "        start = self.num_words_title\n",
    "        if self.use_category:\n",
    "            category = torch.narrow(x, -1, start, 1).squeeze(dim=-1).long()\n",
    "            category_vecs = self.category_dense(self.category_emb(category))\n",
    "            all_vecs.append(category_vecs)\n",
    "            start += 1\n",
    "        if self.use_subcategory:\n",
    "            subcategory = torch.narrow(x, -1, start, 1).squeeze(dim=-1).long()\n",
    "            subcategory_vecs = self.subcategory_dense(self.subcategory_emb(subcategory))\n",
    "            all_vecs.append(subcategory_vecs)\n",
    "\n",
    "        if len(all_vecs) == 1:\n",
    "            news_vecs = all_vecs[0]\n",
    "        else:\n",
    "            all_vecs = torch.stack(all_vecs, dim=1)\n",
    "            \n",
    "            news_vecs = self.final_attn(all_vecs)\n",
    "        return news_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f05fd2f-652d-4eaa-8da0-85f503ff1447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UserEncoder, self).__init__()\n",
    "        news_dim = 400\n",
    "        user_query_vector_dim = 200\n",
    "        self.user_log_length = 50\n",
    "        self.user_log_mask = False\n",
    "        self.attn = AttentionPooling(news_dim, user_query_vector_dim)\n",
    "        self.pad_doc = nn.Parameter(torch.empty(1, news_dim).uniform_(-1, 1)).type(torch.FloatTensor)\n",
    "\n",
    "    def forward(self, news_vecs, log_mask=None):\n",
    "        '''\n",
    "            news_vecs: batch_size, history_num, news_dim\n",
    "            log_mask: batch_size, history_num\n",
    "        '''\n",
    "        bz = news_vecs.shape[0]\n",
    "        if self.user_log_mask:\n",
    "            user_vec = self.attn(news_vecs, log_mask)\n",
    "        else:\n",
    "            padding_doc = self.pad_doc.unsqueeze(dim=0).expand(bz, self.user_log_length, -1)\n",
    "            news_vecs = news_vecs * log_mask.unsqueeze(dim=-1) + padding_doc * (1 - log_mask.unsqueeze(dim=-1))\n",
    "            user_vec = self.attn(news_vecs)\n",
    "        return user_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7515df94-8dc4-44df-80e1-eb5bbd86d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityEncoder(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(EntityEncoder, self).__init__()\n",
    "\n",
    "        self.entity_dim = cfg.entity_emb_dim\n",
    "        self.news_dim = 400\n",
    "\n",
    "        self.mhat = MultiHeadSelfAttention(self.entity_dim, cfg.head_num , cfg.head_dim , cfg.head_dim)\n",
    "        self.mhat_dim = cfg.head_num * cfg.head_dim\n",
    "        self.lnorm = nn.LayerNorm(self.mhat_dim)\n",
    "        self.drop = nn.Dropout(p=cfg.dropout_probability)\n",
    "\n",
    "        self.att = AttentionPooling(self.mhat_dim, cfg.attention_hidden_dim)\n",
    "        self.ln = nn.Linear(self.mhat_dim, self.news_dim)\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, entity_input, entity_mask=None):\n",
    "\n",
    "        batch_size, num_news, num_entity, _ = entity_input.shape\n",
    "        entity_input = entity_input.view(-1, num_entity, self.entity_dim)\n",
    "        entity_input = self.drop(entity_input)\n",
    "        entity_input = self.mhat(entity_input, entity_input, entity_input)\n",
    "        entity_input = self.lnorm(entity_input)\n",
    "\n",
    "        entity_input = self.drop(entity_input)\n",
    "        entity_input = self.att(entity_input)\n",
    "        entity_input = self.lnorm(entity_input)\n",
    "        entity_input = self.ln(entity_input)\n",
    "        entity_input = self.act(entity_input)\n",
    "        \n",
    "        return  entity_input.view(batch_size, num_news, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddaa5be1-8b93-41e0-a685-38c74b4ff8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NAML(torch.nn.Module):\n",
    "    def __init__(self, embedding_matrix, entity_emb, num_category, num_subcategory, **kwargs):\n",
    "        super(NAML, self).__init__()\n",
    "        self.news_dim = 400\n",
    "        self.entity_dim = 100\n",
    "        self.npratio = 4\n",
    "        self.user_log_length = 50\n",
    "        pretrained_word_embedding = torch.from_numpy(embedding_matrix).float()\n",
    "        word_embedding = nn.Embedding.from_pretrained(pretrained_word_embedding,\n",
    "                                                      freeze=False,\n",
    "                                                      padding_idx=0)\n",
    "        \n",
    "        pretrain = torch.from_numpy(entity_emb).float()\n",
    "        self.entity_embedding_layer = nn.Embedding.from_pretrained(pretrain, \n",
    "                                                                   freeze=False, \n",
    "                                                                   padding_idx=0)\n",
    "        \n",
    "        self.news_encoder = NewsEncoder( word_embedding, num_category, num_subcategory)\n",
    "        self.user_att = AttentionPooling(self.news_dim, cfg.attention_hidden_dim)\n",
    "        self.candi_att = AttentionPooling(self.news_dim, cfg.attention_hidden_dim)\n",
    "        self.user_encoder = UserEncoder()\n",
    "        self.entity_encoder = EntityEncoder(cfg)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, history, history_mask, candidate, label):\n",
    "        '''\n",
    "            history: batch_size, history_length, num_word_title\n",
    "            history_mask: batch_size, history_length\n",
    "            candidate: batch_size, 1+K, num_word_title\n",
    "            label: batch_size, 1+K\n",
    "        '''\n",
    "        e_his = history[:,:,-5:]\n",
    "        history = history[:,:,:-5]\n",
    "        e_candi = candidate[:,:,-5:]\n",
    "        candidate = candidate[:,:,:-5]\n",
    "        \n",
    "        # e_his = self.entity_embedding_layer(e_his)\n",
    "        # e_candi = self.entity_embedding_layer(e_candi)\n",
    "        # e_his = self.entity_encoder(e_his, None)\n",
    "        # e_candi = self.entity_encoder(e_candi, None)\n",
    "\n",
    "        # num_words = history.shape[-1]\n",
    "        # candidate = candidate.reshape(-1, num_words)\n",
    "        # candidate = self.news_encoder(candidate).reshape(-1, 1 + self.npratio, self.news_dim)\n",
    "        # candidate = self.candi_att(torch.stack([candidate, e_candi], dim=2).view(-1, 2, self.news_dim))\n",
    "        # candidate = candidate.view(-1, self.npratio+1, self.news_dim)\n",
    "\n",
    "        # history = history.reshape(-1, num_words)\n",
    "        # history = self.news_encoder(history).reshape(-1, self.user_log_length, self.news_dim)\n",
    "        # user_vec = self.user_att(torch.stack([history, e_his], dim=2).view(-1, 2, self.news_dim))\n",
    "        # user_vec = history.view(-1, self.user_log_length, self.news_dim)\n",
    "        \n",
    "        # user_vec = self.user_encoder(user_vec, history_mask)\n",
    "        \n",
    "        # score = torch.bmm(candidate, user_vec.unsqueeze(dim=-1)).squeeze(dim=-1)\n",
    "        # loss = self.loss_fn(score, label)\n",
    "\n",
    "        num_words = history.shape[-1]\n",
    "        candidate_news = candidate.reshape(-1, num_words)\n",
    "        candidate_news_vecs = self.news_encoder(candidate_news).reshape(-1, 1 + self.npratio, self.news_dim)\n",
    "        history_news = history.reshape(-1, num_words)\n",
    "        history_news_vecs = self.news_encoder(history_news).reshape(-1, self.user_log_length, self.news_dim)\n",
    "        user_vec = self.user_encoder(history_news_vecs, history_mask)\n",
    "        score = torch.bmm(candidate_news_vecs, user_vec.unsqueeze(dim=-1)).squeeze(dim=-1)\n",
    "        loss = self.loss_fn(score, label)\n",
    "        \n",
    "        return loss, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39f02757-1e70-4cd5-b950-5b41bdfa1b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Dict length: 12506\n",
      "Have words: 11947\n",
      "Missing rate: 0.0446985446985447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12506"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_dict = pickle.load(open(os.path.join(cfg.data_dir + '_train', \"category_dict.bin\"), \"rb\"))\n",
    "subcategory_dict = pickle.load(open(os.path.join(cfg.data_dir + '_train', \"subcategory_dict.bin\"), \"rb\"))\n",
    "word_dict = pickle.load(open(os.path.join(cfg.data_dir + '_train', \"word_dict.bin\"), \"rb\"))\n",
    "glove_emb = load_pretrain_emb(cfg.glove_path, word_dict, cfg.word_emb_dim)\n",
    "len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42ab74c3-be64-4f83-856c-e0eab5720c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_true, y_hat):\n",
    "    y_hat = torch.argmax(y_hat, dim=-1)\n",
    "    tot = y_true.shape[0]\n",
    "    hit = torch.sum(y_true == y_hat)\n",
    "    return hit.data.float() * 1.0 / tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b1fc4f7-bb86-403e-8582-da8bcf6ad281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAML(\n",
       "  (entity_embedding_layer): Embedding(17586, 100, padding_idx=0)\n",
       "  (news_encoder): NewsEncoder(\n",
       "    (embedding_matrix): Embedding(12507, 300, padding_idx=0)\n",
       "    (category_emb): Embedding(18, 100, padding_idx=0)\n",
       "    (category_dense): Linear(in_features=100, out_features=400, bias=True)\n",
       "    (subcategory_emb): Embedding(265, 100, padding_idx=0)\n",
       "    (subcategory_dense): Linear(in_features=100, out_features=400, bias=True)\n",
       "    (final_attn): AttentionPooling(\n",
       "      (att_fc1): Linear(in_features=400, out_features=200, bias=True)\n",
       "      (att_fc2): Linear(in_features=200, out_features=1, bias=True)\n",
       "    )\n",
       "    (cnn): Conv1d(300, 400, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (attn): AttentionPooling(\n",
       "      (att_fc1): Linear(in_features=400, out_features=200, bias=True)\n",
       "      (att_fc2): Linear(in_features=200, out_features=1, bias=True)\n",
       "    )\n",
       "    (cln): Linear(in_features=300, out_features=400, bias=True)\n",
       "  )\n",
       "  (user_att): AttentionPooling(\n",
       "    (att_fc1): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (att_fc2): Linear(in_features=200, out_features=1, bias=True)\n",
       "  )\n",
       "  (candi_att): AttentionPooling(\n",
       "    (att_fc1): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (att_fc2): Linear(in_features=200, out_features=1, bias=True)\n",
       "  )\n",
       "  (user_encoder): UserEncoder(\n",
       "    (attn): AttentionPooling(\n",
       "      (att_fc1): Linear(in_features=400, out_features=200, bias=True)\n",
       "      (att_fc2): Linear(in_features=200, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (entity_encoder): EntityEncoder(\n",
       "    (mhat): MultiHeadSelfAttention(\n",
       "      (W_Q): Linear(in_features=100, out_features=400, bias=True)\n",
       "      (W_K): Linear(in_features=100, out_features=400, bias=True)\n",
       "      (W_V): Linear(in_features=100, out_features=400, bias=True)\n",
       "      (scaled_dot_product_attn): ScaledDotProductAttention()\n",
       "    )\n",
       "    (lnorm): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "    (drop): Dropout(p=0.2, inplace=False)\n",
       "    (att): AttentionPooling(\n",
       "      (att_fc1): Linear(in_features=400, out_features=200, bias=True)\n",
       "      (att_fc2): Linear(in_features=200, out_features=1, bias=True)\n",
       "    )\n",
       "    (ln): Linear(in_features=400, out_features=400, bias=True)\n",
       "    (act): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NAML(glove_emb, entity_emb, len(category_dict), len(subcategory_dict))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
    "model = model.to(device)\n",
    "torch.set_grad_enabled(True)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "710d3bc3-675e-4a00-91a5-a77c9ccd3475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1809it [02:28, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2471.2314, device='cuda:0') tensor(795.8249, device='cuda:0')\n",
      "EPOCH: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1809it [02:16, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2345.8030, device='cuda:0') tensor(862.1172, device='cuda:0')\n",
      "EPOCH: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1809it [02:16, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2287.4905, device='cuda:0') tensor(891.1859, device='cuda:0')\n",
      "EPOCH: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1809it [02:16, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2237.3159, device='cuda:0') tensor(916.2503, device='cuda:0')\n",
      "EPOCH: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1809it [02:16, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2190.1606, device='cuda:0') tensor(936.8284, device='cuda:0')\n",
      "EPOCH: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1809it [02:17, 13.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2142.3845, device='cuda:0') tensor(962.5068, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ep in range(6):\n",
    "    loss = 0.0\n",
    "    accuary = 0.0\n",
    "    print(\"EPOCH: \" + str(ep))\n",
    "    for cnt, (_, [log_ids, log_mask, input_ids, targets]) in tqdm(enumerate(dataloader)):\n",
    "        log_ids = log_ids.to(device)\n",
    "        log_mask = log_mask.to(device)\n",
    "        input_ids = input_ids.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        bz_loss, y_hat = model(log_ids, log_mask, input_ids, targets)\n",
    "        loss += bz_loss.data.float()\n",
    "        accuary += acc(targets, y_hat)\n",
    "        optimizer.zero_grad()\n",
    "        bz_loss.backward()\n",
    "        optimizer.step()\n",
    "        # stop\n",
    "    print(loss, accuary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619ceb00-d40f-426c-94b3-3bd4646dcfa3",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94ac9e3a-5b13-446f-bf6f-171c99d24cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d066192f-25d9-4a1a-b1c7-dab919a97df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x1abb2b066a0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c734545-520a-4773-90d7-dc0cfa911166",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"val\"\n",
    "data_dir = {\"train\": cfg.data_dir + '_train', \"val\": cfg.data_dir + '_val', \"test\": cfg.data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8710744c-91ff-48f0-8026-9c94c5685323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': './data/MINDsmall_train',\n",
       " 'val': './data/MINDsmall_val',\n",
       " 'test': './data/MINDsmall'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e48bd4e7-628e-4a12-8a7e-78b5328a9b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/MINDsmall_val'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_index_valid = pickle.load(open(Path(data_dir[mode]) / \"news_dict.bin\", \"rb\"))\n",
    "news_input_valid = pickle.load(open(Path(data_dir[mode]) / \"nltk_token_news.bin\", \"rb\"))\n",
    "data_dir[mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49fef80e-89fd-4e64-b218-8401da02d2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65238"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_index_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6768039c-b691-453c-84ba-4b31c9bad228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65239, 27)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_input_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39596d22-f1bc-4945-a650-c38372afeb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dataset = NewsDataset(news_input_valid)\n",
    "news_dataloader = DataLoader(news_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a3ce4-9bea-4357-ac10-841486f56bcf",
   "metadata": {},
   "source": [
    "## news -> scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9142bf3b-4d4e-4094-91bb-5a024a647abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 510/510 [00:01<00:00, 393.52it/s]\n"
     ]
    }
   ],
   "source": [
    "news_scoring = []\n",
    "maxE = 0\n",
    "with torch.no_grad():\n",
    "    for input_ids in tqdm(news_dataloader):\n",
    "        e_lis = input_ids[:,-5:]\n",
    "        input_ids = input_ids[:,:-5].cuda()\n",
    "        news_vec = model.news_encoder(input_ids)\n",
    "        news_vec = news_vec.to(torch.device(\"cpu\"))\n",
    "        news_vec = torch.concatenate((news_vec, e_lis),-1)\n",
    "        news_vec = news_vec.detach().numpy()\n",
    "        news_scoring.extend(news_vec)\n",
    "\n",
    "news_scoring = np.array(news_scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b6dbe-19ba-40a6-89be-ab292c9c0791",
   "metadata": {},
   "source": [
    "## val loader and compute score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e664e0d-dae5-4cb9-b7f3-775b9939472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidDataset_PANEL_1(Dataset_PANEL_1):\n",
    "    def __init__(self, filename, news_index, news_score, cfg, neighbor_dict, news_graph):\n",
    "        super(Dataset_PANEL_1).__init__()\n",
    "        self.filename = filename\n",
    "        self.news_index = news_index\n",
    "        self.news_score = news_score\n",
    "        self.user_log_length = cfg.his_size\n",
    "        self.npratio = cfg.npratio\n",
    "        self.cfg = cfg\n",
    "        self.neighbor_dict = neighbor_dict\n",
    "        self.news_graph = news_graph\n",
    "        self.news_graph.x = self.news_graph.x.float()\n",
    "        self.prepare()\n",
    "\n",
    "    def pad_to_fix_len(self, x, fix_length, padding_front=True, padding_value=0):\n",
    "        if padding_front:\n",
    "            pad_x = [padding_value] * (fix_length - len(x)) + x[-fix_length:]\n",
    "            mask = [0] * (fix_length - len(x)) + [1] * min(fix_length, len(x))\n",
    "        else:\n",
    "            pad_x = x[-fix_length:] + [padding_value] * (fix_length - len(x))\n",
    "            mask = [1] * min(fix_length, len(x)) + [0] * (fix_length - len(x))\n",
    "        return pad_x, np.array(mask, dtype='float32')\n",
    "\n",
    "    def line_mapper(self, line):\n",
    "        line = line.strip().split('\\t')\n",
    "        click_docs = line[3].split()\n",
    "        \n",
    "        candidate_news = self.trans_to_nindex([i.split('-')[0] for i in line[4].split()])\n",
    "        label = [int(i.split('-')[1]) for i in line[4].split()]\n",
    "        actual = len(label)\n",
    "        candidate_news, _ = self.pad_to_fix_len(candidate_news, 200)\n",
    "        label, _ = self.pad_to_fix_len(label, 200, True, -1)\n",
    "        \n",
    "        click_docs = self.trans_to_nindex(click_docs)\n",
    "\n",
    "        # build sub-graph\n",
    "        k_hops_click = self.build_k_hop(click_docs)\n",
    "        \n",
    "        click_docs, log_mask = self.pad_to_fix_len(click_docs, self.user_log_length)\n",
    "        user_feature = self.news_score[click_docs]\n",
    "\n",
    "        news_feature = self.news_score[candidate_news]\n",
    "        \n",
    "        return k_hops_click,  [torch.from_numpy(user_feature), torch.from_numpy(log_mask), \\\n",
    "        torch.from_numpy(news_feature), torch.tensor(label), actual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "098ac2d6-3047-4e0d-8e5f-b33f0d19254e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('data/MINDsmall_val/behaviors_np4_0.tsv')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_file_valid = Path(data_dir[mode]) / f\"behaviors_np4_0.tsv\"\n",
    "target_file_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0cc6c9c4-9065-4ddb-98db-af4381ba7d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_graph_valid = torch.load(Path(data_dir[mode]) / \"nltk_news_graph.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1774a9e9-5684-4d1e-8618-5e154dd20523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10285it [00:05, 1744.39it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = ValidDataset_PANEL_1(\n",
    "                filename=target_file_valid,\n",
    "                news_index=news_index_valid,\n",
    "                news_score=news_scoring,\n",
    "                cfg=cfg,\n",
    "                neighbor_dict=news_neighbors_dict,\n",
    "                news_graph=news_graph_valid\n",
    ")\n",
    "valid_dataloader = GraphDataLoader(valid_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "093e3b3e-214a-4958-a7bd-dbe9c8f4f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_metrics(cnt, x):\n",
    "    print(cnt, x)\n",
    "\n",
    "def get_mean(arr):\n",
    "    return [np.array(i).mean() for i in arr]\n",
    "\n",
    "def get_sum(arr):\n",
    "    return [np.array(i).sum() for i in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c70af8bf-0d03-4900-bab4-7913cd5ab743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 400) torch.Size([128, 200, 400]) (128, 200)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multi_class must be in ('ovo', 'ovr')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     47\u001b[0m score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(news_vec, user_vec)\n\u001b[1;32m---> 48\u001b[0m auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m mrr \u001b[38;5;241m=\u001b[39m mrr_score(label, score)\n\u001b[0;32m     50\u001b[0m ndcg5 \u001b[38;5;241m=\u001b[39m ndcg_score(label, score, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\dangkh\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\dangkh\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:633\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    627\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial AUC computation not available in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    628\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass setting, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_fpr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    629\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set to `None`, received `max_fpr=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    630\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(max_fpr)\n\u001b[0;32m    631\u001b[0m         )\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multi_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 633\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_class must be in (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _multiclass_roc_auc_score(\n\u001b[0;32m    635\u001b[0m         y_true, y_score, labels, multi_class, average, sample_weight\n\u001b[0;32m    636\u001b[0m     )\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: multi_class must be in ('ovo', 'ovr')"
     ]
    }
   ],
   "source": [
    "AUC = []\n",
    "MRR = []\n",
    "nDCG5 = []\n",
    "nDCG10 = []\n",
    "\n",
    "for cnt, (_, [log_vecs, log_mask, news_vecs, labels, actualSizes]) in tqdm(enumerate(valid_dataloader)):\n",
    "    log_vecs = log_vecs.cuda()\n",
    "    log_mask = log_mask.cuda()\n",
    "    # news_vecs = news_vecs.cuda()\n",
    "    \n",
    "\n",
    "    e_his = log_vecs[:,:,-5:].int()\n",
    "    log_vecs = log_vecs[:,:,:-5]\n",
    "    e_candi = news_vecs[:,:,-5:].int()\n",
    "    news_vecs = news_vecs[:,:,:-5]\n",
    "\n",
    "    # e_his = model.entity_embedding_layer(e_his)\n",
    "    # e_candi = model.entity_embedding_layer(e_candi)\n",
    "    # e_his = model.entity_encoder(e_his, None)\n",
    "    # e_candi = model.entity_encoder(e_candi, None)\n",
    "    \n",
    "    # user_vecs = model.user_att(torch.stack([log_vecs, e_his], dim=2).view(-1, 2, model.news_dim))\n",
    "    # user_vecs = user_vecs.view(-1, model.user_log_length, model.news_dim)\n",
    "\n",
    "    user_vecs = log_vecs.view(-1, model.user_log_length, model.news_dim)\n",
    "\n",
    "    \n",
    "    user_vecs = model.user_encoder(user_vecs, log_mask).to(torch.device(\"cpu\")).detach().numpy()\n",
    "    \n",
    "    # news_vecs = model.candi_att(torch.stack([news_vecs, e_candi], dim=2).view(-1, 2, model.news_dim))\n",
    "    # news_vecs = news_vecs.unsqueeze(0).to(torch.device(\"cpu\")).detach().numpy()\n",
    "\n",
    "    \n",
    "    # candidate = candidate.view(-1, model.npratio+1, self.news_dim)\n",
    "    # (1, 400) torch.Size([1, 22, 400]) (1, 22)\n",
    "\n",
    "    labels = labels.to(torch.device(\"cpu\")).detach().numpy()\n",
    "    print(user_vecs.shape, news_vecs.shape, labels.shape)\n",
    "\n",
    "    for user_vec, news_vec, label, actualSize in zip(user_vecs, news_vecs, labels, actualSizes):\n",
    "        news_vec = news_vec[actualSize.item():,:]\n",
    "        label = label[actualSize.item():]\n",
    "        stop\n",
    "        tmp = np.mean(label)\n",
    "        if tmp == 0 or tmp == 1:\n",
    "            continue\n",
    "\n",
    "        score = np.dot(news_vec, user_vec)\n",
    "        auc = roc_auc_score(label, score)\n",
    "        mrr = mrr_score(label, score)\n",
    "        ndcg5 = ndcg_score(label, score, k=5)\n",
    "        ndcg10 = ndcg_score(label, score, k=10)\n",
    "\n",
    "        AUC.append(auc)\n",
    "        MRR.append(mrr)\n",
    "        nDCG5.append(ndcg5)\n",
    "        nDCG10.append(ndcg10)\n",
    "\n",
    "    if cnt % 10000 == 0:\n",
    "        print_metrics(cnt, get_mean([AUC, MRR, nDCG5, nDCG10]))\n",
    "\n",
    "print_metrics(cnt, get_mean([AUC, MRR, nDCG5, nDCG10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
